{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7a95fc0-584c-4686-8216-278cddd4d2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Shape: (5, 13)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The test_size = 1 should be greater or equal to the number of classes = 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 36\u001b[0m\n\u001b[0;32m     33\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoan_Status\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# âš–ï¸ Stratified Split to Preserve Class Balance\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[0;32m     37\u001b[0m     X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, stratify\u001b[38;5;241m=\u001b[39my)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# ðŸ§  Train Logistic Regression\u001b[39;00m\n\u001b[0;32m     40\u001b[0m lr \u001b[38;5;241m=\u001b[39m LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2872\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2868\u001b[0m         CVClass \u001b[38;5;241m=\u001b[39m ShuffleSplit\n\u001b[0;32m   2870\u001b[0m     cv \u001b[38;5;241m=\u001b[39m CVClass(test_size\u001b[38;5;241m=\u001b[39mn_test, train_size\u001b[38;5;241m=\u001b[39mn_train, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m-> 2872\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X\u001b[38;5;241m=\u001b[39marrays[\u001b[38;5;241m0\u001b[39m], y\u001b[38;5;241m=\u001b[39mstratify))\n\u001b[0;32m   2874\u001b[0m train, test \u001b[38;5;241m=\u001b[39m ensure_common_namespace_device(arrays[\u001b[38;5;241m0\u001b[39m], train, test)\n\u001b[0;32m   2876\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m   2877\u001b[0m     chain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[0;32m   2878\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[0;32m   2879\u001b[0m     )\n\u001b[0;32m   2880\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:1909\u001b[0m, in \u001b[0;36mBaseShuffleSplit.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   1879\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[0;32m   1880\u001b[0m \n\u001b[0;32m   1881\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1906\u001b[0m \u001b[38;5;124;03mto an integer.\u001b[39;00m\n\u001b[0;32m   1907\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1908\u001b[0m X, y, groups \u001b[38;5;241m=\u001b[39m indexable(X, y, groups)\n\u001b[1;32m-> 1909\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_indices(X, y, groups):\n\u001b[0;32m   1910\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m train, test\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2331\u001b[0m, in \u001b[0;36mStratifiedShuffleSplit._iter_indices\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   2326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe train_size = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m should be greater or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2328\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mequal to the number of classes = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (n_train, n_classes)\n\u001b[0;32m   2329\u001b[0m     )\n\u001b[0;32m   2330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_test \u001b[38;5;241m<\u001b[39m n_classes:\n\u001b[1;32m-> 2331\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2332\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe test_size = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m should be greater or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2333\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mequal to the number of classes = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (n_test, n_classes)\n\u001b[0;32m   2334\u001b[0m     )\n\u001b[0;32m   2336\u001b[0m \u001b[38;5;66;03m# Find the sorted list of instances for each class:\u001b[39;00m\n\u001b[0;32m   2337\u001b[0m \u001b[38;5;66;03m# (np.unique above performs a sort, so code is O(n logn) already)\u001b[39;00m\n\u001b[0;32m   2338\u001b[0m class_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msplit(\n\u001b[0;32m   2339\u001b[0m     np\u001b[38;5;241m.\u001b[39margsort(y_indices, kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmergesort\u001b[39m\u001b[38;5;124m\"\u001b[39m), np\u001b[38;5;241m.\u001b[39mcumsum(class_counts)[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   2340\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: The test_size = 1 should be greater or equal to the number of classes = 2"
     ]
    }
   ],
   "source": [
    "# ðŸ“¦ Import Libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# ðŸ“¥ Load Dataset\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "print(\"Original Shape:\", df.shape)\n",
    "\n",
    "# ðŸ” Handle Missing Values\n",
    "df['Gender'] = df['Gender'].fillna(df['Gender'].mode()[0])\n",
    "df['Married'] = df['Married'].fillna(df['Married'].mode()[0])\n",
    "df['Dependents'] = df['Dependents'].fillna(df['Dependents'].mode()[0])\n",
    "df['Self_Employed'] = df['Self_Employed'].fillna(df['Self_Employed'].mode()[0])\n",
    "df['LoanAmount'] = df['LoanAmount'].fillna(df['LoanAmount'].median())\n",
    "df['Loan_Amount_Term'] = df['Loan_Amount_Term'].fillna(df['Loan_Amount_Term'].mode()[0])\n",
    "df['Credit_History'] = df['Credit_History'].fillna(df['Credit_History'].mode()[0])\n",
    "\n",
    "# ðŸ”  Label Encoding\n",
    "cols = ['Gender', 'Married', 'Education', 'Self_Employed', 'Property_Area', 'Loan_Status', 'Dependents']\n",
    "le = LabelEncoder()\n",
    "for col in cols:\n",
    "    df[col] = le.fit_transform(df[col].astype(str))\n",
    "\n",
    "# âœ… Define Features and Target\n",
    "X = df.drop(['Loan_ID', 'Loan_Status'], axis=1)\n",
    "y = df['Loan_Status']\n",
    "\n",
    "# âš–ï¸ Stratified Split to Preserve Class Balance\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# ðŸ§  Train Logistic Regression\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "acc_lr = accuracy_score(y_test, y_pred_lr)\n",
    "\n",
    "# ðŸŒ³ Train Decision Tree\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "acc_dt = accuracy_score(y_test, y_pred_dt)\n",
    "\n",
    "# ðŸ Select Best Model\n",
    "if acc_dt > acc_lr:\n",
    "    print(\"âœ… Using Decision Tree Classifier\")\n",
    "    best_model = dt\n",
    "    y_pred = y_pred_dt\n",
    "    acc = acc_dt\n",
    "else:\n",
    "    print(\"âœ… Using Logistic Regression\")\n",
    "    best_model = lr\n",
    "    y_pred = y_pred_lr\n",
    "    acc = acc_lr\n",
    "\n",
    "# ðŸ“ˆ Evaluation\n",
    "print(f\"\\nðŸ”¢ Accuracy: {acc:.2f}\")\n",
    "print(\"\\nðŸ“Š Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred, labels=[0,1]))\n",
    "print(\"\\nðŸ“„ Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e165d5c-1688-4306-b107-6ef448a3413b",
   "metadata": {},
   "source": [
    "# ðŸ§  Task 2: Credit Risk Prediction\n",
    "\n",
    "## ðŸŽ¯ Objective\n",
    "Predict whether a loan applicant is likely to default on a loan using classification techniques on the Loan Prediction dataset.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“¥ Step 1: Load and Inspect the Dataset\n",
    "\n",
    "We will now load the `train.csv` file and check the structure and first few records of the dataset.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§¹ Step 2: Data Cleaning\n",
    "\n",
    "Let's check and fill in missing values using appropriate strategies:\n",
    "- Mode for categorical features\n",
    "- Median for numeric features\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”¤ Step 3: Label Encoding\n",
    "\n",
    "We convert categorical variables like `Gender`, `Education`, etc. into numeric values using LabelEncoder.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“Š Step 4: Exploratory Data Analysis (EDA)\n",
    "\n",
    "We visualize key features to understand trends in the data.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ¤– Step 5: Model Training\n",
    "\n",
    "We split the dataset and train a Logistic Regression model.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“ˆ Step 6: Model Evaluation\n",
    "\n",
    "We evaluate using accuracy, confusion matrix, and classification report.\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Conclusion\n",
    "\n",
    "- Logistic Regression is able to classify loan approvals fairly well.\n",
    "- Feature trends such as income and education play an important role.\n",
    "- Model can be further improved with tuning and additional feature engineering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a325d4-d0cd-4534-9c77-e2b3d5bcfa16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
